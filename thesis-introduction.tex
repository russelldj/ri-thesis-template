% -*- mode:LaTex; mode:visual-line; mode:flyspell; fill-column:75-*-

\chapter{Introduction} \label{chapIntroduction}
Forests impact many aspects of our life on Earth, such as removing CO\textsubscript{2} from the atmosphere, purifying water, moderating local temperature, and supporting human livelihoods. Unfortunately, forests are under threat from a variety of sources including climate change, invasive species, fire, and direct human pressures \cite{IPCC2019ClimateReport}. This is causing forests to change at an unprecedented rate. In light of these rapid changes, it is critical that we have up-to-date information to inform decisions such as habitat preservation, sustainable timber operations, forest fire mitigation, and carbon sequestration. In this thesis, we develop approaches motivated by forest fire mitigation and carbon sequestration, but these methods aim to be generic enough to also be suitable for other applications. 

There are many sources of data that can be used to inform forest management. This thesis studies three representative sources of data: manual field measurements, data from drones, and remote sensing imagery. The manual measurements are accurate and granular but fail to provide information at scale. Conversely, remote sensing data can provide information at scale, but lacks fine-grained spatial detail and is challenging to interpret. Drone data strikes a middle ground. The goal of this work is to develop techniques that leverage all three sources of data to produce insights about forests that are both accurate and scalable. 


\section{Research Questions}
We propose the following concept for an intelligent future forest management system: First, a forester goes to a new area and collects a limited number of representative field observations for a task of interest, such as vegetation mapping or detecting trees, and then surveys the same areas with a drone. Second, the system uses these observations to train a machine learning model to perform this task on new drone data. Third, the system uses remote sensing data to propose a set of representative locations to visit with the drone. The forester conducts the drone flights and ingests this data into the system. Fourth, predictions are generated for this new data using the previously trained model. Finally, these predictions are used to train a model that generates predictions from remote sensing data for the entire region. This concept leverages the forester's domain knowledge to obtain ground truth measurements and uses both drones and remote sensing to incrementally scale these observations to a large region.

As initial steps toward this concept, we propose the following three research questions:
\begin{itemize}
    \item How can data from field surveys, drones, and remote sensing be integrated to accurately detect trees at scale?
\end{itemize}
\begin{itemize}
    \item How can drones be used to classify vegetation types in a large forested region?
\end{itemize}
\begin{itemize}
    \item How can sparse drone surveys be planned to provide the most diverse and informative measurements about a region?
\end{itemize}

\section{Methods}
A challenge in conducting this research is the limited availability of applicable datasets. Therefore, we begin this work by collecting data in a diverse set of forests using both a commodity drone and a custom multi-sensor payload. We extract geometric information from this data using two different approaches, structure from motion and simultaneous localization and mapping.

To study tree detection, we generate an orthomosaic from the drone data using structure from motion and then label the location of a small number of trees. Then, we register this data with aerial remote sensing data. Finally, we explore several strategies for applying a deep learning tree detector with different combinations of these modalities.

For vegetation mapping, we use a LiDAR-based simultaneous localization and mapping approach to understand the structure of the scene. Then we determine the types of vegetation using an image-based semantic segmentation approach. These predictions are aggregated into a 3D representation that captures both the structure of the environment and what type of vegetation is present at each location.

To plan informative drone flights, we begin with remote sensing data for the region. Using an unsupervised method, we extract informative texture features. These features are then used to model the uncertainty of unobserved points given a set of observations. Using this uncertainty model, we incrementally plan the set of locations to observe over an entire drone flight. This plan seeks to minimize the uncertainty of the entire region while still maintaining feasibility under the battery constraints. 

\section{Contributions}
We find that structure from motion is a powerful tool for processing over-canopy drone flights using only GPS-tagged images and requires minimal hand-tuning. In an under-canopy setting, a LiDAR-based simultaneous localization and mapping approach demonstrated better performance but this requires more complex sensors and site-specific parameter tuning. 

Our experiments on tree detection are consistent with previous results showing that trees can be easily detected in drone data and that site-specific fine-tuning with a small amount of data only yields a small improvement. We find that applying the model that was trained on a diverse set of drone data to aerial remote sensing data yields poor performance. Fine-tuning the model for remote sensing data results in a moderate increase in quality but the quality of these detections is still insufficient for most tasks. Training a remote sensing model using predictions from the drone yields an improvement over the pre-trained model. However, training on a small amount of labeled data is still more effective.

In the fuel mapping setting, we find that modern transformer-based semantic segmentation networks can generate adequate predictions by training on only a small number of labeled images from the same scene. We show that this network can be used in combination with the LiDAR-based SLAM to build a metric-semantic map of the world that captures both the geometry and the classification of each region. This allows us to conduct vegetation class mapping automatically with a drone.

Finally, we show that random kernels and dimensionality reduction yields informative unsupervised features. These allow us to perform land-cover mapping with a simple k-nearest neighbor classifier. We evaluate the informative path planning approach on a variety of locations and show that even though the paths look qualitatively reasonable, the quality of the improvement is small compared to the variability between the different trials. This highlights the challenge of building generalizable informative path planning approaches and suggests that further characterization of what samples are informative is required.


We conclude with suggestions for how to unify multiple themes from these experiments. We recommend further studying the effects of spatial resolution on tree detection by simulating a range of resolutions from high-resolution drone data. We suggest that semantic mapping can be made more robust and accessible by using structure from motion rather than simultaneous localization and mapping to predict geometry. We propose that the work on semantic mapping, informative path planning, and remote sensing predictions can be integrated into a comprehensive field experiment to directly address the feasibility of the conceptualized forest understanding system. Finally, we highlight the need for more interdisciplinary datasets and open-source software to foster further work in this space.