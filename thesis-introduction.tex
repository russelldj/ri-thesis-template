% -*- mode:LaTex; mode:visual-line; mode:flyspell; fill-column:75-*-

\chapter{Introduction} \label{chapIntroduction}
Forests impact many aspects of our life on earth, ranging from the composition of the atmosphere, purification of water, moderating local temperature, and contributing to fire risk \cite{IPCC2019ClimateReport}. Unfortunately, they are under threat from a variety of factors including climate change, invasive species, fire, and direct human pressures. This is causing forests to change at an unprecedented rate. In light of these rapid changes, it is critical that we have up-to-date information to inform decisions such as habitat preservation, sustainable timber operations, forest fire mitigation, and carbon sequestration. In this work we specifically study aspects of forest fire mitigation and carbon sequestration, though the approaches aim to be generic enough to scale to other applications. 

There are many sources of data that can be used to inform forest management. In this work we study three: manual field measurements, data from drones, and remote sensing imagery. The manual measurements are accurate and granular, but fail to provide information at scale. Conversely, remote sensing data can provide information at scale, but lacks fine-grained spatial detail and is challenging to interpret. Drone data strikes a middle ground between these extremes. The goal of this work is to develop techniques that leverage all three sources of data to produce insights about forests that are both accurate and scalable.
\section{Research Questions}
Our broad goal of multi-modality forest understanding motivates three specific areas of study:
\begin{itemize}
    \item How can data from field surveys, drones, and remote sensing be integrated to accurately detect trees at scale?
\end{itemize}
\begin{itemize}
    \item How can drones be used to classify vegetation type in a large forested region?
\end{itemize}
\begin{itemize}
    \item How can sparse drone surveys be planned to provide the most diverse and informative measurements about a region?
\end{itemize}

%\section{Methods}
%\section{Conclusions}
%Most traditional cameras only capture three different bands of light, red, green and blue. In contrast, many space-borne sensors capture more spectral bands and are termed either multi- or hyper-spectral. Multispectral data has coarse bands with gaps between them, while hyperspectral data has many small bands which observe a near-continuous spectral signal \cite{Lu2019ComparingProperties}. These sensors vary widely in spatial resolution with legacy government satellites such as Landsat 8 and Sentinel 2 having resolutions of multiple meters per pixel. More recent commercial offerings have pushed the resolution to the sub-meter range. 


%In this work, we focus on optical data, since it is conceptually most similar to what we capture from drones. This data is collected by an electro-optical sensor which takes images of the earth. Then, the images are registered together and referenced into absolute geospatial coordinates. This process relies on the estimated pose of the platform when the image was taken, the height of the ground, and manual corrections. From there, an orthographic render is generated. This is a projection of the data into a top-down view, which is commonly aligned with the axes of geospatial coordinate system used to define the location. Many satellite data sources capture bands outside of the visible wavelength. Sensors which capture a x to y number of bands are termed multi-spectral and sensors which captured y to z bands are termed hyper-spectral. 
%\begin{itemize}
%    \item talk about what what sat is 
%    \item Sat data has a broad extent and may be too low res
%    \item Reannalysis has shown that accuracy is often very low \cite{} 
%    \item Data products from crewed aircraft has higher resolution but require substaintial investment and planning
%\end{itemize}

%Another option is "grid coverage" where a lawnmower pattern is executed twice, in perpendicular directions. An important consideration when executing these surveys is the drone altitude, which represents a trade-off between coverage ability and spatial resolution. While drones can in theory fly to a substantial altitude, they are restricted in the US to 400ft and below due to concerns about interfering with crewed aircraft. The final consideration is front- and side-overlap. Front overlap refers to the fraction of the image which is observed in two consecutive frames captured as the drone is flying forward. The side overlap refers to how much overlap there is between neighboring flight lines.
