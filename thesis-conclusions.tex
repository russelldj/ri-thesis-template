% -*- mode:LaTex; mode:visual-line; mode:flyspell; fill-column:75-*-

\chapter{Conclusions} \label{chapConclusions}
The goal of this work is to take initial steps toward integrated intelligent forest management. The experiments we conducted span a variety of topics, but some common themes emerged. The first is that structure from motion is a powerful tool for drone-based mapping and should likely be explored before resorting to more complex multi-sensor SLAM solutions. The second general trend is that often the most effective way to generate deep learning predictions is by annotating a small amount of high-quality and relevant data, rather than relying on higher volumes of lower-quality annotations. This suggests that specializing individual models to a given scene is more promising than trying to have one static model that covers the full variability of a task. Finally, these experiments show significantly more compelling results when using drone data as opposed to remote sensing data. As remote sensing technology improves, the role of drones may deminish, but this scenario appears unlikely in the near future.  

\section{Key Takeaways}
We find that the structure from motion parameters suggested by Young et. al. \cite{Young2022} work well for reconstructing a number of diverse datasets. The performance is the best when the drone conducts a lawnmower survey above the canopy but manual non-overlapping flight can produce acceptable results. It is more challenging to generate reconstructions from images taken under the canopy, but further research may be able to address this issue.

We compare the performance of tree detection from both drone and NAIP data. The detections from drone data are still significantly better than those from NAIP data, even after resampling to the same resolution.

This work demonstrates an approach to map the location of different types of vegetation using a drone equipped with a camera and LiDAR. We show that recent transformer-based semantic segmentation models are able to achieve moderate performance when trained on very few images from a target region. We show that the local structure of these maps is accurate, but the global structure is highly dependent on the quality of the SLAM predictions.

We show that unsupervised feature extraction is a powerful tool for land-cover classification from remote sensing data. Specifically, using the approach described in MOSAIKS and compressing these features with PCA yields a compact and informative representation. These features can be used to plan informative drone flights by choosing samples that minimize Gaussian Process uncertainty about the whole region. This approach results in a very small improvement in accuracy for the first flights but this converges after all four flights have been conducted. The proposed approach is better than a coverage planner at identifying rare classes, no matter how many flights have been executed. However, it's important to note that the variance in prediction quality is high for both metrics and further study is required to draw rigorous conclusions.
\\
\\
This can be summarized briefly by a set of techniques that we found effective:
\begin{itemize}
    \item Infering 3D geometry with SfM on over-canopy drone data
    \item Infering 3D geometry with a well-tuned SLAM system on under-canopy drone data
    \item Detecting trees in drone-derived ortho-mosaics using deep learning
    \item Training semantic segmentation models on low numbers of images
    \item Performing semantic mapping with image-based semantic segmentation and 
    \item Extracting semantically-meaningful unsupervised features using MOSAIKS \cite{Rolf2021} and PCA
\\
\\
\end{itemize}
The following set of techniques yielded unsatisfactory or inconclusive results:
\begin{itemize}
    \item SfM in under-canopy environments
    \item Training tree detection models on aerial data from NAIP using either manual annotations or drone predictions
    \item Informative path planning for dramatically-better land cover mapping sample selection
\end{itemize}


%\begin{itemize}
%    \item Structure from motion is a powerful tool to build 3D maps from drone images with minimal assumptions
%    \item A small amount of annotated data can be very useful to train deep learning models for a given natural environment
%    \item Predicting trees at increasingly-low resolutions yields better results 
%\end{itemize}
\section{Contributions}
This work makes several contributions:
\begin{itemize}
    \item We collect drone datasets in a variety of forest settings and implement software infastructure to process this data.
    \item We conduct experiments evaluating the performance of tree detection on drone and remote sensing data. 
    \item We present a system for mapping different types of vegetation using multi-senors  SLAM for geometric information and vision-based semantic segmentation to differentiate vegetation classes. This has applications to forest fire mitigation and we believe this is the first system of its kind to address this problem. 
    \item We propose a novel long-horizon informative path planner that is applicable for planning sparse surveys with commodity drones. We demonstrate that this method is helpful for choosing samples for a land-cover classification task when it is important to identify rare classes.
\end{itemize}

%\begin{itemize}
%    \item Adding semantics to meshes 
%    \item Adding height information to semantics and tree detection images
%    \item Automatically registering data at different scales using trees as features
%    \item Evaluating the performance of different feature extractors
%\end{itemize}
        
%\section{Proposed Concluding Experiments}
%There are several additional experiments that we anticipate completing before the conclusion of this thesis.
%For tree detection, it is clear that we need a quantitative assessment to better understand the tradeoffs between these different approaches.We plan to conduct a two-fold evaluation scheme by repeating the same steps we did on \textit{Stowe} on another dataset we collected in the same region. Then, we will evaluate the predictions from approaches trained on one location on the other, and vice versa, to get an accurate assessment of the ability of these approaches to generalize. We also propose to add two more experiments to the existing ones. These involve fine-tuning a model for aerial data on predicted tree locations from the drone data. In one case we used predictions from the pretrained model and in the other case we use predictions from the fine-tuned model. We hypothesize that this multi-stage approach will increase performance because of the increased diversity of training examples.  

%We also would like to more thoroughly evaluate the sensitivity of RAPTORS to different parameter choices. We will first begin by assessing the impact of different parameters on the feature extraction side and different machine learning models for land cover predictions. Once we have settled on a desirable combination, we will run system-level experiments on the RAPTORS algorithm. Since these experiments are relatively computationally intensive, we will explore a number of parameters at once using randomized sampling. We will also test the algorithm on data from more diverse geographic regions.

\section{Future Work}
% Start big picture
From our tree detection experiments, we conclude that applying existing tree detectors to NAIP data does not result in useful predictions. However, testing whether other remote sensing data is better would be an interesting direction for future work. Commercially-available satellite products have superior resolution and would only require moderate up-sampling to match the resolution that is used for tree detection. One way to study this phenomenon without additional data would be to simulate satellite data by downsampling the drone-derived orthomosaic to the appropriate resolution. 

In this work, we have demonstrated an online semantic mapping system that uses a custom multi-sensor payload. A logical extension to this method would be using only GPS-tagged images from commodity drones as input. Fortunately, SfM operating on these images can be used to replace the geometric reasoning provided by SLAM. Aggregating multi-view semantic information with meshes has been shown to be an effective strategy for 3D semantic mapping. As an additional improvement, geometric data from the meshes could be used to augment the visual data for semantic segmentation. Rendering techniques could be used to compute which point on the mesh corresponds to each pixel in the image. Geometric information from the mesh, such as height, could then be added as an additional input to the semantic segmentation network.

One way to integrate all the themes in this work would be to conduct real-world informative path planning experiments. This would involve planning a path with RAPTORS, classifying the drone data with the demonstrated semantic mapping or proposed semantic meshes approach, and then generating predictions from unsupervised features using the drone plots as training samples. The quality of these predictions could be assessed either by using an existing dataset as ground truth or by flying an exhaustive drone survey and using this as a pseudo-ground truth. 

A central theme of this work is conducting experiments where limited ground truth data exists. This makes thorough analysis challenging and limits participation in forestry robotics. Future research should focus on collecting annotated datasets that are informed by best practices from both the robotics and ecology communities. This will ensure that a diverse set of technical experiments are possible and that the questions they address provide ecologically relevant answers.